{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is used to extract Sentinel image data and other layers for a set of \n",
    "# soil sample point locations. The DN values for each of the image bands and other \n",
    "# layers is output as a dictionary of tabular data that can be processed using the \n",
    "# \"StockSOC_ProcessPoints\" script. Input files are ESRI Shapefiles with the project \n",
    "# boundary polygon and the soil sample points locations.A Python pickle file is \n",
    "# exported to be input into the \"StockSOC_ProcessPoints\" script.\n",
    "\n",
    "# This script was written by Ned Horning [ned.horning@regen.network]\n",
    "\n",
    "# This script is free software; you can redistribute it and/or modify it under the\n",
    "# terms of the Apache License 2.0 License.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from geemap import geojson_to_ee, ee_to_geojson\n",
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c35b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter start and end date as numbers for year, month, day ###\n",
    "startDate = ee.Date.fromYMD(2021, 1, 1)\n",
    "endDate = ee.Date.fromYMD(2021, 12, 31)\n",
    "# Enter the seasonal portion for each year in the date range to process\n",
    "startMonth = 1  \n",
    "endMonth = 12\n",
    "\n",
    "# Scale (resolution) in meters for the analysis\n",
    "pixScale = 20\n",
    "\n",
    "# Cloud masking parameters - for more information about the workflow and avriables see:\n",
    "# https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless\n",
    "cloudFilter = 60\n",
    "cloudProbabilityThreshold = 50\n",
    "nirDarkThreshold = 0.15\n",
    "cloudPProjectedDistance = 1\n",
    "buffer = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter input and output file paths and names ###\n",
    "boundaryShp = \"/home/nedhorning/RegenNetwork/Soils/Ruuts/LaEmma/LaEmmaBoundary.shp\"\n",
    "inPoints = \"/home/nedhorning/RegenNetwork/Soils/Ruuts/LaEmma/LaEmmaSamplePoints2021.shp\"\n",
    "outPickle = \"/home/nedhorning/RegenNetwork/Soils/Ruuts/LaEmma/GEE_Output/extractedPoints.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f75e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get image data and apply cloud/shadow filter\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "        .filterBounds(aoi)\n",
    "        #.filterMetadata('MGRS_TILE', 'equals', '14SKJ')  # Use this to specify a specific tile\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.calendarRange(startMonth, endMonth,'month'))\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cloudFilter)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud cover function\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(cloudProbabilityThreshold).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c58076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(nirDarkThreshold*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, cloudPProjectedDistance *10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focal_min(2).focal_max(buffer*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "# return img.addBands(is_cld_shdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba85b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76dd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function make the server-side feature collection accessible to the client\n",
    "def getValues(fc):\n",
    "    features = fc.getInfo()['features']\n",
    "    dictarr = []\n",
    "    for f in features:\n",
    "        attr = f['properties']\n",
    "        dictarr.append(attr)\n",
    "    return dictarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input boundary Shapefile to a GEE boundary feature to constrain spatial extent\n",
    "boundary_ee = geemap.shp_to_ee(boundaryShp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image data using temporal and spatial constraints\n",
    "s2_sr_cld_col = get_s2_sr_cld_col(boundary_ee, startDate, endDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ef86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cloud/shadow mask and add NDVI layer\n",
    "sentinelCollection = (s2_sr_cld_col.map(add_cld_shdw_mask)\n",
    "                             .map(apply_cld_shdw_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dates for all images in the collection\n",
    "datesObject = sentinelCollection.aggregate_array(\"system:time_start\")\n",
    "dateList =  datesObject.getInfo()\n",
    "dateList=[datetime.fromtimestamp(x/1000).strftime('%Y_%m_%d') for x in dateList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image display parameters\n",
    "sentinel_vis = {\n",
    "    'min': 0,\n",
    "    'max': 2500,\n",
    "    'gamma': [1.1],\n",
    "    'bands': ['B4', 'B3', 'B2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input sample points Shapefile to a GEE feature\n",
    "points_ee = geemap.shp_to_ee(inPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store all points\n",
    "allPoints = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdab686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Topographic wetness index and extract points\n",
    "upslopeArea = (ee.Image(\"MERIT/Hydro/v1_0_1\")\n",
    "    .select('upa'))\n",
    "elv = (ee.Image(\"MERIT/Hydro/v1_0_1\")\n",
    "    .select('elv'))\n",
    "\n",
    "slope = ee.Terrain.slope(elv)\n",
    "upslopeArea = upslopeArea.multiply(1000000).rename('UpslopeArea')\n",
    "slopeRad = slope.divide(180).multiply(math.pi)\n",
    "TWI = ee.Image.log(upslopeArea.divide(slopeRad.tan())).rename('TWI')\n",
    "extractedPointsTWI = geemap.extract_values_to_points(points_ee, TWI, scale=pixScale)\n",
    "dictarrTWI = getValues(extractedPointsTWI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and extract points for continuous heat-insolation load index and extract points\n",
    "chili = (ee.Image(\"CSP/ERGo/1_0/Global/SRTM_CHILI\"))\n",
    "extractedPointsCHILI = geemap.extract_values_to_points(points_ee, chili, scale=pixScale)\n",
    "dictarrCHILI = getValues(extractedPointsCHILI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e048ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the images for processing\n",
    "images = sentinelCollection.toList(sentinelCollection.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088391a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Map=geemap.Map()\n",
    "Map.centerObject(boundary_ee, 13)\n",
    "for index in range(0, sentinelCollection.size().getInfo()-1):\n",
    "    print(\"Processing \" + dateList[index] + \": \" + str(sentinelCollection.size().getInfo()-1 - index - 1) + \" images to go      \", end = \"\\r\")\n",
    "    image = ee.Image(images.get(index))\n",
    "    extractedPoints = geemap.extract_values_to_points(points_ee, image, scale=pixScale)\n",
    "    dictarr = getValues(extractedPoints)\n",
    "    points = gpd.GeoDataFrame(dictarr)\n",
    "    # Add the following variables to the collection of point data\n",
    "    points['stock'] = points['BD'] * points['C%']\n",
    "    points['twi'] = gpd.GeoDataFrame(dictarrTWI)['first']\n",
    "    points['chili'] = gpd.GeoDataFrame(dictarrCHILI)['first']\n",
    "    \n",
    "    # Use band 3 to select only points not covered by clouds\n",
    "    if ('B3' in points):  \n",
    "        allPoints.update({dateList[index] : points})\n",
    "    # Add the image layer for display\n",
    "    Map.addLayer(image, sentinel_vis, dateList[index])\n",
    "\n",
    "# Add boundary to dispay images\n",
    "Map.addLayer(boundary_ee, {}, \"Boundary EE\")\n",
    "\n",
    "# Display the map.\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the dictionary with all points - this will be input to the \"StockSOC_ProcessPoints\" Notebook\n",
    "with open(outPickle, 'wb') as handle:\n",
    "    pickle.dump(allPoints, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a list of all the image dates\n",
    "list(allPoints.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all of the points starting with the earliest date\n",
    "allPoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
